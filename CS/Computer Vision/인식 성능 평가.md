# 인식 성능 평가

새로운 알고리즘을 개발하거나 기존 알고리즘 중 주어진 문제에 적합한 것을 선택하여 해결한다.

그럼 어떻게 인식 성능을 측정할까?

## 혼동 행렬 (Confusion Matrix)

혼동 행렬은 모델의 성능을 평가할 때 사용되는 지표이다. 이를 이해하기 위해 알아야 할 4가지 개념이 존재한다.

1. TP(True Positive) : 맞는 것을 올바르게 맞다고 예측함
2. TN(True Negative) : 아닌 것을 올바르게 틀리다고 예측함
3. FP(False Positive) : 아닌 것을 올바르지 않게 맞다고 예측함
4. FN(False Negative) : 맞는 것을 올바르지 않게 틀리다고 예측함

> True/False는 올바르게/올바르지 않게 예측했음을 의미, Positive/Negative는 맞다고/틀리다고 얘측했음을 의미

<img src="https://github-production-user-asset-6210df.s3.amazonaws.com/67703882/246885934-ae6bbb0d-3e8e-4e3f-8722-bc967f006ef8.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20230619%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20230619T163009Z&X-Amz-Expires=300&X-Amz-Signature=0adefb254bbc45131482df026872b8729c32fdb3eb2131b27569fc9c030208bb&X-Amz-SignedHeaders=host&actor_id=67703882&key_id=0&repo_id=400976668" />

위 표에서 nij는 wi에 속하는 샘플을 wj로 분류한 것의 개수를 의미한다. 예를 들어 n11은 w1을 w1로 옳게 분류한 샘플의 개수이고 n12는 w1을 w2로 틀리게 분류한 샘플의 개수이다.

## 참/거짓 긍정률, 참/거짓 부정률

- 거짓 긍정률(False Positive Rate)은 거짓으로 긍정될 확률, 즉 거짓을 맞다고 **틀리게** 예측한 확률을 의미한다.

  ```
  FPR = FP / (FP+TN) = n21 / (n21+n22)
  ```

  > 거짓을 예측한 것 중 참이라고 예측해버린 비율

- 거짓 부정률(False Negative Rate)은 거짓으로 부정될 확률, 즉 참을 거짓으로 **틀리게** 예측한 확률을 의미한다.

  ```
  FNR = FN / (TP+FN) = n12 / (n11+n12)
  ```

  > 참을 예측한 것 중에 거짓이라고 예측해버린 비율

- 참 긍정률(True Positive Rate)은 참으로 긍정될 확률, 즉 참을 맞다고 잘 예측한 확률을 의미한다.

  ```
  TPR = TP /(TP+FN) = n11 / (n11+n12)
  ```

- 참 부정률(True Negative Rate)은 참으로 부정될 확률, 거짓을 맞다고 잘 예측한 확률을 의미한다.

  ```
  TNR = TN / (FP+TN) = n22 / (n21+n22)
  ```

## 정인식률, 정확율, 재현율

- 정인식률은 정확하게(올바르게) 평가한 확률을 의미한다.

  - `(TP+TN) / (TP+TN+FP+FN)`
  - 1 - 불량률

- 정확률(Precesion)은 **참이라고** 평가한 항목 중에서 진짜 참인 확률을 의미한다.
  - 참인 애 / 참인데 참으로 나온 애 + 거짓인데 참으로 나온 애
  - `TP / (TP+FP)`
- 재현율(Recall)은 **참을** 평가한 항목 중에 진짜 참인 확률을 의미한다.
  - 참인 애 / 참인데 참으로 나온 애 + 참인데 거짓으로 나온 애
  - `TP / (TP+FN)`

## 참고자료

- [혼동행렬](https://lebi.tistory.com/5)

- [패턴 인식](https://luv-n-interest.tistory.com/540)
